---
title: Evaluation and Benchmarking 
layout: post
---

### Evaluation and Benchmarking (e.g. Atari Learning Environment, OpenAI Gym, GVGAI)

* GVGAI - [<a href='http://www.gvgai.net/'>url</a>]
* Games one can find on Github and that have been adapted to work with OpenAI Gym (e.g. Mario, Zelda, etc)
* GDL [<a href='http://games.stanford.edu/games/gdl.html'>url</a>]
* Toribash [<a href='https://www.toribash.com/'>url</a>]
* OpenAI Gym [<a href='https://gym.openai.com/'>url</a>]
* FightingICE [<a href='http://www.ice.ci.ritsumei.ac.jp/~ftgaic/index-2.html'>url</a>]
* ALE (Atari Learning Environment) [<a href='https://github.com/mgbellemare/Arcade-Learning-Environment'>url</a>]
* I have created benchmarks for pathfinding that are broadly used: [<a href='http://movingai.com/benchmarks/'>url</a>]

<hr><center><img src='assets/png/q11-wordcloud.png' /></center>